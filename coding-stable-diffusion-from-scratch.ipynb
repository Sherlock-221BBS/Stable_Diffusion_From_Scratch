{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.nn import functional as F\nimport math\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:36:44.838710Z","iopub.execute_input":"2024-01-04T18:36:44.839827Z","iopub.status.idle":"2024-01-04T18:36:48.918857Z","shell.execute_reply.started":"2024-01-04T18:36:44.839784Z","shell.execute_reply":"2024-01-04T18:36:48.917699Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:36:55.670511Z","iopub.execute_input":"2024-01-04T18:36:55.671026Z","iopub.status.idle":"2024-01-04T18:36:55.680376Z","shell.execute_reply.started":"2024-01-04T18:36:55.670991Z","shell.execute_reply":"2024-01-04T18:36:55.678926Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cpu'"},"metadata":{}}]},{"cell_type":"code","source":"\nclass SelfAttention(nn.Module):\n    def __init__(self, n_heads, d_embed, in_proj_bias = True, out_proj_bias = True):\n        super().__init__()\n        self.in_proj = nn.Linear(in_features = d_embed, out_features = d_embed * 3, bias = in_proj_bias)\n        self.out_proj = nn.Linear(in_features = d_embed, out_features = d_embed, bias = out_proj_bias)\n        self.n_heads = n_heads\n        self.d_head = d_embed // n_heads\n\n    def forward(self, x, causal_mask = False):\n        input_shape = x.shape\n        batch, seq_len, d_embed = input_shape\n\n        q, k, v = self.in_proj(x).chunk(3, dim = -1)\n        interim_shape = (batch, seq_len, self.n_heads, self.d_head)\n\n        q = q.reshape(interim_shape).transpose(1, 2)\n        k = k.reshape(interim_shape).transpose(1, 2)\n        v = v.reshape(interim_shape).transpose(1, 2)\n\n        weights = q @ k.transpose(-1, -2)\n\n        if causal_mask:\n            mask = torch.ones_like(weights, dtype = torch.bool).triu(1)\n            weights.masked_fill(mask, -torch.inf)\n        weights /= math.sqrt(self.d_head)\n        weights = F.softmax(weights, dim = -1)\n\n        outputs = weights @ v\n        outputs = outputs.transpose(1, 2)\n        outputs = outputs.reshape(input_shape)\n        outputs = self.out_proj(outputs)\n        return outputs\n\n\nclass CrossAttention(nn.Module):\n    def __init__(self, n_heads, d_embed, d_cross, proj_in_bias = True, proj_out_bias = True):\n        super().__init__()\n        self.q_proj = nn.Linear(d_embed, d_embed, bias = proj_in_bias)\n        self.k_proj = nn.Linear(d_cross, d_embed, bias = proj_in_bias)\n        self.v_proj = nn.Linear(d_cross, d_embed, bias = proj_in_bias)\n        self.n_heads = n_heads\n        self.d_head = d_embed // n_heads\n        self.out_proj = nn.Linear(d_embed, d_embed)\n\n    def forward(self, x, context):\n        input_shape = x.shape\n        batch, seq_len, d_embed = input_shape \n\n        q = self.q_proj(x)\n        k = self.k_proj(context)\n        v = self.v_proj(context)\n\n        interim_shape = (batch, -1, self.n_heads, self.d_head)\n        q = q.reshape(interim_shape).transpose(1, 2)\n        k = k.reshape(interim_shape).transpose(1, 2)\n        v = v.reshape(interim_shape).transpose(1, 2)\n\n        weights = q @ k.transpose(-1, -2)\n        weights/= math.sqrt(self.d_head)\n        outputs = weights @ v\n\n        outputs = outputs.transpose(1, 2)\n        outputs = outputs.reshape(input_shape)\n        outputs = self.out_proj(outputs)\n        return outputs\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:00.167717Z","iopub.execute_input":"2024-01-04T18:37:00.168124Z","iopub.status.idle":"2024-01-04T18:37:00.189786Z","shell.execute_reply.started":"2024-01-04T18:37:00.168095Z","shell.execute_reply":"2024-01-04T18:37:00.188506Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# x = torch.randn(1, 64 * 64, 640)\n# context = torch.randn(1, 77, 768)\n# self_attention = SelfAttention(10, 640)\n# out = self_attention(x)\n# out.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:03.413508Z","iopub.execute_input":"2024-01-04T18:37:03.414645Z","iopub.status.idle":"2024-01-04T18:37:03.419435Z","shell.execute_reply.started":"2024-01-04T18:37:03.414607Z","shell.execute_reply":"2024-01-04T18:37:03.418047Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# VAE Helper Classes","metadata":{}},{"cell_type":"code","source":"class VAE_AttentionBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.groupnorm = nn.GroupNorm(32, channels)\n        self.attention = SelfAttention(1, channels)\n\n    def forward(self, x):\n        residue = x\n        x = self.groupnorm(x)\n        n, c, h, w = x.shape\n        x = x.view((n, c, h * w))\n        x = x.transpose(-1, -2)\n        x = self.attention(x)\n        x = x.view((n, c, h, w))\n        return x + residue\n\nclass VAE_ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.groupnorm_1 = nn.GroupNorm(32, in_channels)\n        self.conv_1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1)\n        self.groupnorm_2 = nn.GroupNorm(32, out_channels)\n        self.conv_2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding = 1)\n        if in_channels == out_channels:\n            self.residual_layer = nn.Identity()\n        else:\n            self.residual_layer = nn.Conv2d(in_channels, out_channels, kernel_size = 3,padding = 1)\n\n    def forward(self, x):\n        residue = x\n        x = self.groupnorm_1(x)\n        x = F.silu(x)\n        x = self.conv_1(x)\n        x = self.groupnorm_2(x)\n        x = F.silu(x)\n        x = self.conv_2(x)\n        print(\"successfully passed\")\n        return x + self.residual_layer(residue)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:04.026713Z","iopub.execute_input":"2024-01-04T18:37:04.027129Z","iopub.status.idle":"2024-01-04T18:37:04.040760Z","shell.execute_reply.started":"2024-01-04T18:37:04.027095Z","shell.execute_reply":"2024-01-04T18:37:04.039633Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# VAE Encoder","metadata":{}},{"cell_type":"code","source":"class VAE_Encoder(nn.Sequential):\n    def __init__(self):\n        super().__init__(\n            nn.Conv2d(in_channels = 3,out_channels = 128, kernel_size = 3, padding = 1),\n            VAE_ResidualBlock(128, 128),\n            VAE_ResidualBlock(128, 128),\n            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 2, padding = 0),\n            VAE_ResidualBlock(128, 256),\n            VAE_ResidualBlock(256, 256),\n            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 2, padding = 0),\n            VAE_ResidualBlock(256, 512),\n            VAE_ResidualBlock(512, 512),\n            nn.Conv2d(in_channels = 512, out_channels =512, kernel_size = 3, stride = 2, padding =0),\n            VAE_ResidualBlock(512, 512),\n            VAE_ResidualBlock(512, 512),\n            VAE_ResidualBlock(512, 512),\n            VAE_AttentionBlock(512),\n            VAE_ResidualBlock(512, 512),\n            nn.GroupNorm(32, 512),\n            nn.SiLU(),\n            nn.Conv2d(in_channels = 512, out_channels = 8, kernel_size = 3, padding =1)\n        )\n\n\n    def forward(self, x, noise):\n        for module in self:\n            if getattr(module, \"stride\", None) == (2, 2):\n                x = F.pad(x, (0, 1, 0, 1))\n\n            x = module(x)\n\n        mean, log_variance = x.chunk(2, dim = 1)\n        log_variance = torch.clamp(log_variance, min = -30, max = 20)\n        variance = log_variance.exp()\n        std_dev = variance.sqrt()\n        x = mean + noise * std_dev\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:06.776593Z","iopub.execute_input":"2024-01-04T18:37:06.777023Z","iopub.status.idle":"2024-01-04T18:37:06.790196Z","shell.execute_reply.started":"2024-01-04T18:37:06.776985Z","shell.execute_reply":"2024-01-04T18:37:06.788942Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# vae_encoder = VAE_Encoder()\n# input = torch.randn(1, 3, 512, 512)\n# noise = torch.randn(1, 4, 64, 64)\n# encoder_outputs = vae_encoder(input, noise)\n# encoder_outputs.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:08.488237Z","iopub.execute_input":"2024-01-04T18:37:08.489003Z","iopub.status.idle":"2024-01-04T18:37:08.493147Z","shell.execute_reply.started":"2024-01-04T18:37:08.488944Z","shell.execute_reply":"2024-01-04T18:37:08.492273Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# VAE Decoder","metadata":{}},{"cell_type":"code","source":"class VAE_Decoder(nn.Sequential):\n      def __init__(self):\n        super().__init__(\n            nn.Conv2d(4, 4, kernel_size = 1, padding = 0),\n            nn.Conv2d(4, 512, kernel_size = 3, padding = 1),\n            VAE_ResidualBlock(512, 512),\n            VAE_AttentionBlock(512),\n            VAE_ResidualBlock(512, 512),\n            VAE_ResidualBlock(512, 512),\n            VAE_ResidualBlock(512, 512),\n            VAE_ResidualBlock(512, 512),\n            nn.Upsample(scale_factor = 2),\n            nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n            VAE_ResidualBlock(512, 512),\n            VAE_ResidualBlock(512, 512),\n            VAE_ResidualBlock(512, 512),\n            nn.Upsample(scale_factor = 2),\n            nn.Conv2d(512, 512, kernel_size = 3, padding =1),\n            VAE_ResidualBlock(512, 256),\n            VAE_ResidualBlock(256, 256),\n            VAE_ResidualBlock(256, 256),\n            nn.Upsample(scale_factor = 2),\n            nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n            VAE_ResidualBlock(256, 128),\n            VAE_ResidualBlock(128, 128),\n            VAE_ResidualBlock(128, 128),\n            nn.GroupNorm(32, 128),\n            nn.SiLU(),\n            nn.Conv2d(128, 3, kernel_size = 3, padding = 1)\n\n        )\n\n        def forward(self, x):\n            x /= 0.18125\n            for module in self:\n                x = module(x)\n\n            return x","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:11.285930Z","iopub.execute_input":"2024-01-04T18:37:11.286608Z","iopub.status.idle":"2024-01-04T18:37:11.298713Z","shell.execute_reply.started":"2024-01-04T18:37:11.286573Z","shell.execute_reply":"2024-01-04T18:37:11.297444Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# vae_decoder = VAE_Decoder()\n# decoder_output = vae_decoder(encoder_outputs)\n# decoder_output.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:12.857644Z","iopub.execute_input":"2024-01-04T18:37:12.858050Z","iopub.status.idle":"2024-01-04T18:37:12.862878Z","shell.execute_reply.started":"2024-01-04T18:37:12.858016Z","shell.execute_reply":"2024-01-04T18:37:12.861756Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# CLIP","metadata":{}},{"cell_type":"code","source":"class CLIPEmbedding(nn.Module):\n    def __init__(self, n_vocab, n_embd, n_tokens):\n        super().__init__()\n        self.embedding = nn.Embedding(n_vocab, n_embd)\n        self.positional_embedding = nn.Parameter(torch.randn(n_tokens, n_embd))\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x+= self.positional_embedding\n        return x\n\n\nclass CLIPLayer(nn.Module):\n    def __init__(self, n_head, n_embd):\n        super().__init__()\n        self.layernorm_1 = nn.LayerNorm(n_embd)\n        self.attention = SelfAttention(n_head, n_embd)\n\n        self.layernorm_2 = nn.LayerNorm(n_embd)\n\n        self.linear_1 = nn.Linear(n_embd, 4 * n_embd)\n        self.linear_2 = nn.Linear(4 * n_embd, n_embd)\n\n    def forward(self, x):\n        residue = x\n        x = self.layernorm_1(x)\n        x = self.attention(x, causal_mask = True)\n        x+= residue\n\n        residue = x\n        x = self.layernorm_2(x)\n        x = self.linear_1(x)\n        x = x * torch.sigmoid(1.702 * x)\n        x = self.linear_2(x)\n\n        x+= residue\n        return x\n\nclass CLIP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.embedding = CLIPEmbedding(49708, 768, 77)\n        self.layers = nn.ModuleList([\n            CLIPLayer(12, 768) for i in range(12)\n        ])\n        self.layernorm = nn.LayerNorm(768)\n\n\n    def forward(self, tokens):\n        tokens = tokens.type(torch.long)\n        state = self.embedding(tokens)\n\n        for layer in self.layers:\n            state = layer(state)\n\n        output = self.layernorm(state)\n\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:15.009646Z","iopub.execute_input":"2024-01-04T18:37:15.010073Z","iopub.status.idle":"2024-01-04T18:37:15.025384Z","shell.execute_reply.started":"2024-01-04T18:37:15.010039Z","shell.execute_reply":"2024-01-04T18:37:15.024088Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Diffusion Helper Classes","metadata":{}},{"cell_type":"code","source":"class TimeEmbedding(nn.Module):\n    def __init__(self, n_embd):\n        super().__init__()\n        self.linear_1 = nn.Linear(n_embd, 4 * n_embd)\n        self.linear_2 = nn.Linear(4 * n_embd, 4 * n_embd)\n\n    def forward(self, time):\n        time = self.linear_1(time)\n        time = F.silu(time)\n        time = self.lienar_2(time)\n        return time \n\nclass UNET_ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, n_time = 1280):\n        super().__init__()\n        self.groupnorm_feature = nn.GroupNorm(32, in_channels)\n        self.conv_feature = nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding =1)\n        self.linear_time = nn.Linear(n_time, out_channels)\n        self.groupnorm_merged =  nn.GroupNorm(32, out_channels)\n        self.conv_merged = nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding = 1)\n\n        if in_channels == out_channels:\n            self.residual_layer = nn.Identity()\n        else:\n            self.residual_layer = nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1)\n\n    def forward(self, feature, time):\n        residue = feature\n\n        feature = self.groupnorm_feature(feature)\n        feature = F.silu(feature)\n        feature = self.conv_feature(feature)\n\n        time = F.silu(time)\n        time = self.linear_time(time)\n        merged = feature + time.unsqueeze(-1).unsqueeze(-1)\n        merged = self.groupnorm_merged(merged)\n        merged = self.conv_merged(merged)\n\n        return merged + self.residual_layer(residue)\n\n\nclass UNET_AttentionBlock(nn.Module):\n    def __init__(self, n_heads, n_embed, d_context = 768):\n        super().__init__()\n        channels = n_heads * n_embed\n        self.groupnorm = nn.GroupNorm(32, channels)\n        self.conv_in = nn.Conv2d(channels, channels, kernel_size = 1, padding = 0)\n    \n        self.layernorm_1 = nn.LayerNorm(channels)\n        self.attention = SelfAttention(n_heads, channels)\n\n        self.layernorm_2 = nn.LayerNorm(channels)\n        self.cross_attention = CrossAttention(n_heads, channels, d_context)\n\n        self.layernorm_3= nn.LayerNorm(channels)\n        self.linear_geglu1 = nn.Linear(channels, 4 * channels * 2)\n        self.linear_geglu2 = nn.Linear(channels * 4, channels)\n\n        self.conv_out = nn.Conv2d(channels, channels, kernel_size = 1, padding = 0)\n\n    def forward(self, x, context):\n        residue_long = x\n\n        x = self.groupnorm(x)\n        x = self.conv_in(x)\n\n        n, c, h, w = x.shape\n        x = x.view((n, c, h * w))\n        x = x.transpose(-1, -2)\n\n\n        residue_short = x\n        x = self.layernorm_1(x)\n        print(x.shape)\n        x = self.attention(x)\n        x+= residue_short \n\n        residue_short = x\n        x = self.layernorm_2(x)\n        x = self.cross_attention(x, context)\n        x+= residue_short\n\n        residue_short = x\n        x = self.layernorm_3(x)\n        x = self.linear_geglu1(x)\n        x, gate = x.chunk(2, dim = -1)\n        x = x * F.gelu(gate)\n        x = self.linear_geglu2(x)\n\n        x = x.transpose(-1, -2)\n        x = x.view((n, c,  h, w))\n\n        return self.conv_out(x) + residue_long\n\n\n\nclass UpSample(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.conv = nn.Conv2d(channels, channels, kernel_size = 3, padding = 1)\n    \n\n    def forward(self, x):\n        x = F.interpolate(x, scale_factor = 2, mode = 'nearest')\n        return self.conv(x)\n\n\n\nclass SwitchSequential(nn.Sequential):\n    def forward(self, x, context, time):\n        for layer in self:\n            if isinstance(layer, UNET_ResidualBlock):\n                x = layer(x, time)\n            elif isinstance(layer, UNET_AttentionBlock):\n                x = layer(x, context)\n            else:\n                x = layer(x)\n\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:23.253654Z","iopub.execute_input":"2024-01-04T18:37:23.254057Z","iopub.status.idle":"2024-01-04T18:37:23.282594Z","shell.execute_reply.started":"2024-01-04T18:37:23.254026Z","shell.execute_reply":"2024-01-04T18:37:23.281690Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Diffusion UNET","metadata":{}},{"cell_type":"code","source":"class UNET(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.ModuleList([\n            SwitchSequential(nn.Conv2d(4, 320, kernel_size = 3, padding = 1)),\n            SwitchSequential(UNET_ResidualBlock(320, 320), UNET_AttentionBlock(8, 40)),\n            SwitchSequential(UNET_ResidualBlock(320, 320), UNET_AttentionBlock(8, 40)), \n            \n            SwitchSequential(nn.Conv2d(320, 320, kernel_size = 3, stride = 2, padding = 1)), \n            SwitchSequential(UNET_ResidualBlock(320, 640), UNET_AttentionBlock(8, 80)), \n            SwitchSequential(UNET_ResidualBlock(640, 640), UNET_AttentionBlock(8, 80)), \n            \n            SwitchSequential(nn.Conv2d(640, 640, kernel_size = 3, stride = 2, padding = 1)), \n            SwitchSequential(UNET_ResidualBlock(640, 1280), UNET_AttentionBlock(8, 160)), \n            SwitchSequential(UNET_ResidualBlock(1280, 1280), UNET_AttentionBlock(8, 160)), \n            \n            SwitchSequential(nn.Conv2d(1280, 1280, kernel_size = 3, stride = 2, padding = 1)), \n            SwitchSequential(UNET_ResidualBlock(1280, 1280)), \n            SwitchSequential(UNET_ResidualBlock(1280, 1280))\n        ])\n        \n        self.bottleneck = SwitchSequential(\n            UNET_ResidualBlock(1280, 1280), \n            UNET_AttentionBlock(8, 160), \n            UNET_ResidualBlock(1280, 1280)\n            )\n        \n        self.decoder = nn.ModuleList([\n            SwitchSequential(UNET_ResidualBlock(2560, 1280)), \n            SwitchSequential(UNET_ResidualBlock(2560, 1280)), \n            SwitchSequential(UNET_ResidualBlock(2560, 1280), UpSample(1280)), \n            \n            SwitchSequential(UNET_ResidualBlock(2560, 1280), UNET_AttentionBlock(8, 160)), \n            SwitchSequential(UNET_ResidualBlock(2560, 1280), UNET_AttentionBlock(8, 160)), \n            SwitchSequential(UNET_ResidualBlock(1920, 1280), UNET_AttentionBlock(8, 160), UpSample(1280)), \n            \n            SwitchSequential(UNET_ResidualBlock(1920, 640), UNET_AttentionBlock(8, 80)), \n            SwitchSequential(UNET_ResidualBlock(1280, 640), UNET_AttentionBlock(8, 80)), \n            SwitchSequential(UNET_ResidualBlock(960, 640), UNET_AttentionBlock(8, 80), UpSample(640)), \n            \n            SwitchSequential(UNET_ResidualBlock(960, 320), UNET_AttentionBlock(8, 40)), \n            SwitchSequential(UNET_ResidualBlock(640, 320), UNET_AttentionBlock(8, 40)), \n            SwitchSequential(UNET_ResidualBlock(640, 320), UNET_AttentionBlock(8, 40))\n        ])\n        \n    def forward(self, x, context, time):\n        skip_connections = []\n        for layer in self.encoder:\n            x = layer(x, context, time)\n            skip_connections.append(x)\n            \n        x = self.bottleneck(x, context, time)\n        for layer in self.decoder:\n            x = torch.cat([x, skip_connections.pop()], dim = 1)\n            x = layer(x, context, time)\n            \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:28.672910Z","iopub.execute_input":"2024-01-04T18:37:28.673336Z","iopub.status.idle":"2024-01-04T18:37:28.692326Z","shell.execute_reply.started":"2024-01-04T18:37:28.673294Z","shell.execute_reply":"2024-01-04T18:37:28.691117Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"x = torch.randn(1, 4, 64, 64)\ncontext = torch.randn(1, 77, 768)\ntime = torch.randn(1, 1280)\n\nunet = UNET()\nout = unet(x, context, time)\nout.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-04T18:37:35.697277Z","iopub.execute_input":"2024-01-04T18:37:35.697755Z","iopub.status.idle":"2024-01-04T18:38:02.883756Z","shell.execute_reply.started":"2024-01-04T18:37:35.697712Z","shell.execute_reply":"2024-01-04T18:38:02.882655Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"torch.Size([1, 4096, 320])\ntorch.Size([1, 4096, 320])\ntorch.Size([1, 1024, 640])\ntorch.Size([1, 1024, 640])\ntorch.Size([1, 256, 1280])\ntorch.Size([1, 256, 1280])\ntorch.Size([1, 64, 1280])\ntorch.Size([1, 256, 1280])\ntorch.Size([1, 256, 1280])\ntorch.Size([1, 256, 1280])\ntorch.Size([1, 1024, 640])\ntorch.Size([1, 1024, 640])\ntorch.Size([1, 1024, 640])\ntorch.Size([1, 4096, 320])\ntorch.Size([1, 4096, 320])\ntorch.Size([1, 4096, 320])\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 320, 64, 64])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}